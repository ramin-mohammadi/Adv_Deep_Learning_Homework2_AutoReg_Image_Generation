{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AutoRegressive Training Using GPU\n",
        "- CPU trains extremely slow (1 epoch takes about 20 mins)\n",
        "- so have to use a gpu\n",
        "- NOTE: in train.py, use Lightning module which automatically moves model and data we're using (training and validation) onto GPU if it exists\n",
        "- so only have to move variables in autoregressive.py interacting with the model onto the GPU\n",
        "- Look at deeplearning Homework3 as example of using GPU, in the models.py we had to move the model and data used for training and validation onto the gpu,\n",
        "- but bc in train.py, trainers for each respective model inherit the lightning module and we place it in a lightning.Trainer(), the model and training/validation data is automatically placed onto gpu if a gpu is existing and available"
      ],
      "metadata": {
        "id": "JPUIBNLmP2K9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect to a T4 GPU"
      ],
      "metadata": {
        "id": "_oQ1j9o_VrFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup\n",
        "- unfortunately will have to manually create the following folders and drag and drop every session\n",
        "  - data\n",
        "    - only place tokenized_train.pth and tokenized_val.pth in here\n",
        "  - checkpoints\n",
        "    - dont have to put anything in here\n",
        "  - homework\n",
        "    - place all .py files that were in homework folder in here\n",
        "  - logs\n",
        "    - dont have to put anything in here\n",
        "  - lastly place requirements.txt in root\n"
      ],
      "metadata": {
        "id": "8XwWaYOKUyRo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3Gi7WgwPrrO",
        "outputId": "0f0e1ac7-0249-44a6-8f8f-021c0d56af9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire>=0.7.0 (from -r requirements.txt (line 1))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lightning>=2.5.0 (from -r requirements.txt (line 2))\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Collecting numpy>=2.2.1 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (11.1.0)\n",
            "Requirement already satisfied: tqdm>=4.66.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.7.0->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (2024.10.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning>=2.5.0->-r requirements.txt (line 2))\n",
            "  Downloading lightning_utilities-0.14.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.0->-r requirements.txt (line 2)) (24.2)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning>=2.5.0->-r requirements.txt (line 2))\n",
            "  Downloading torchmetrics-1.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.5.0->-r requirements.txt (line 2)) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning>=2.5.0->-r requirements.txt (line 2))\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.1->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.1->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.1->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (3.11.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning>=2.5.0->-r requirements.txt (line 2)) (75.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.1->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.5.0->-r requirements.txt (line 2)) (3.10)\n",
            "Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.1-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.3-py3-none-any.whl (931 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.7/931.7 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=9752eccb4d7cc1372ef89457fb91bf43a96159ccb3f699cacbe86236c506fabd\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, lightning-utilities, fire, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fire-0.7.0 lightning-2.5.0.post0 lightning-utilities-0.14.1 numpy-2.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.3\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ6fGmSZTM3q",
        "outputId": "659062e7-a91d-44af-bfa6-16366999a657"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6B6HRS-5TVhb",
        "outputId": "96982d92-0927-415e-de67-51a2d6dcab15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-03-15 00:58:17.642087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742000297.924109    1937 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742000298.002956    1937 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-15 00:58:18.607165: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.train AutoregressiveModel --epochs 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FicnZzFiTZ-d",
        "outputId": "010fafc5-74dd-45d4-f4cf-92cff8140106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "2025-03-16 17:10:02.560770: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742145002.582869   20503 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742145002.589498   20503 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-16 17:10:02.613252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                | Params | Mode \n",
            "------------------------------------------------------\n",
            "0 | model | AutoregressiveModel | 3.8 M  | train\n",
            "------------------------------------------------------\n",
            "3.8 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.8 M     Total params\n",
            "15.285    Total estimated model params size (MB)\n",
            "65        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
            "Epoch 0: 100% 821/821 [07:26<00:00,  1.84it/s, v_num=0, train/loss=2.42e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:05<00:05,  3.87it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 40/40 [00:10<00:00,  3.77it/s]\u001b[A\n",
            "Epoch 1: 100% 821/821 [07:30<00:00,  1.82it/s, v_num=0, train/loss=1.66e+3, validation/loss=3.05e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:05<00:05,  3.86it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 40/40 [00:10<00:00,  3.77it/s]\u001b[A\n",
            "Epoch 2: 100% 821/821 [07:30<00:00,  1.82it/s, v_num=0, train/loss=1.79e+3, validation/loss=2.91e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:05<00:05,  3.86it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 40/40 [00:10<00:00,  3.77it/s]\u001b[A\n",
            "Epoch 3: 100% 821/821 [07:30<00:00,  1.82it/s, v_num=0, train/loss=1.43e+3, validation/loss=2.82e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:05<00:05,  3.86it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 40/40 [00:10<00:00,  3.76it/s]\u001b[A\n",
            "Epoch 4: 100% 821/821 [07:29<00:00,  1.82it/s, v_num=0, train/loss=2.11e+3, validation/loss=2.83e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:05<00:05,  3.87it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 40/40 [00:10<00:00,  3.77it/s]\u001b[A\n",
            "Epoch 5: 100% 821/821 [07:30<00:00,  1.82it/s, v_num=0, train/loss=1.6e+3, validation/loss=2.83e+3] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:05<00:05,  3.85it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 40/40 [00:10<00:00,  3.76it/s]\u001b[A\n",
            "Epoch 6: 100% 821/821 [07:29<00:00,  1.82it/s, v_num=0, train/loss=1.24e+3, validation/loss=2.74e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]       \u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:05<00:05,  3.89it/s]\u001b[A\n",
            "Validation DataLoader 0: 100% 40/40 [00:10<00:00,  3.79it/s]\u001b[A\n",
            "Epoch 7:  22% 180/821 [01:38<05:52,  1.82it/s, v_num=0, train/loss=1.4e+3, validation/loss=2.71e+3] "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Images"
      ],
      "metadata": {
        "id": "omuUSPrUNS__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a folder called gen_images"
      ],
      "metadata": {
        "id": "dz9GcDrtheKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.generation homework/BSQPatchAutoEncoder.pth homework/AutoregressiveModel.pth 8 ./gen_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0cZAGqYNXmH",
        "outputId": "ee5633b0-af83-4f8a-b100-731123b8d61f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1422: indexSelectLargeIndex: block: [66,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/content/homework/generation.py\", line 38, in <module>\n",
            "    Fire(generation)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fire/core.py\", line 135, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "                                ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/fire/core.py\", line 684, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/homework/generation.py\", line 28, in generation\n",
            "    generations = ar_model.generate(n_images, h, w, device=device)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/homework/autoregressive.py\", line 319, in generate\n",
            "    pred = self.forward(img)\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/homework/autoregressive.py\", line 241, in forward\n",
            "    x=torch.roll(x, shifts=1, dims=1) # shfit along token dimension so dim 1 (batch x sequence_len x embded_dim)\n",
            "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Grading"
      ],
      "metadata": {
        "id": "MHfSvK6J0rg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m grader homework -vv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-THa2XrC0uRJ",
        "outputId": "4a2f3256-6313-4bff-f7e3-8a0cd2f6e48c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val grader loaded.\n",
            "\u001b[32m[DEBUG    00:00:000] \u001b[0m\u001b[32mLoading assignment\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:015] \u001b[0m\u001b[32mLoading grader\u001b[0m\n",
            "\u001b[97m[INFO     00:00:016] \u001b[0m\u001b[97mPatch AutoEncoder\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\u001b[32m[DEBUG    00:00:017] \u001b[0m\u001b[32mLoading PatchAutoEncoder from /content/homework/PatchAutoEncoder.pth\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:225] \u001b[0m\u001b[33m  - Image Reconstruction MSE Loss                      [ 0 / 30 ZeroDivisionError ]\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:225] \u001b[0m\u001b[31mTraceback (most recent call last):\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:225] \u001b[0m\u001b[31m  File \"/content/grader/grader.py\", line 64, in wrapper\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:225] \u001b[0m\u001b[31m    v = func(self, **a)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:225] \u001b[0m\u001b[31m        ^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:225] \u001b[0m\u001b[31m  File \"/content/grader/tests.py\", line 61, in test_validation_loss\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:225] \u001b[0m\u001b[31m    mean_loss = sum(losses) / len(losses)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:225] \u001b[0m\u001b[31m                ~~~~~~~~~~~~^~~~~~~~~~~~~\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:225] \u001b[0m\u001b[31mZeroDivisionError: division by zero\u001b[0m\n",
            "\u001b[97m[INFO     00:00:225] \u001b[0m\u001b[97m --------------------------------------------------    [   0 /  30 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:00:226] \u001b[0m\u001b[97mBSQ Patch AutoEncoder\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:227] \u001b[0m\u001b[32mLoading BSQPatchAutoEncoder from /content/homework/BSQPatchAutoEncoder.pth\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:313] \u001b[0m\u001b[33m  - Image Reconstruction MSE Loss                      [ 0 / 30 ZeroDivisionError ]\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:313] \u001b[0m\u001b[31mTraceback (most recent call last):\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:313] \u001b[0m\u001b[31m  File \"/content/grader/grader.py\", line 64, in wrapper\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:313] \u001b[0m\u001b[31m    v = func(self, **a)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:313] \u001b[0m\u001b[31m        ^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:313] \u001b[0m\u001b[31m  File \"/content/grader/tests.py\", line 61, in test_validation_loss\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:313] \u001b[0m\u001b[31m    mean_loss = sum(losses) / len(losses)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:313] \u001b[0m\u001b[31m                ~~~~~~~~~~~~^~~~~~~~~~~~~\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:313] \u001b[0m\u001b[31mZeroDivisionError: division by zero\u001b[0m\n",
            "\u001b[97m[INFO     00:00:313] \u001b[0m\u001b[97m --------------------------------------------------    [   0 /  30 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:00:315] \u001b[0m\u001b[97mAutoregressive Model\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:318] \u001b[0m\u001b[32mLoading AutoregressiveModel from /content/homework/AutoregressiveModel.pth\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:334] \u001b[0m\u001b[32mLoading BSQPatchAutoEncoder from /content/homework/BSQPatchAutoEncoder.pth\u001b[0m\n",
            "Compute validation autoregressive loss: 0it [00:00, ?it/s]\n",
            "\u001b[33m[WARNING  00:00:415] \u001b[0m\u001b[33m  - Autoregressive prediction loss                     [ 0 / 15 ZeroDivisionError ]\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:415] \u001b[0m\u001b[31mTraceback (most recent call last):\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:415] \u001b[0m\u001b[31m  File \"/content/grader/grader.py\", line 64, in wrapper\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:415] \u001b[0m\u001b[31m    v = func(self, **a)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:415] \u001b[0m\u001b[31m        ^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:415] \u001b[0m\u001b[31m  File \"/content/grader/tests.py\", line 141, in test_validation_loss\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:415] \u001b[0m\u001b[31m    mean_loss = total_loss / len(dataloader)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:415] \u001b[0m\u001b[31m                ~~~~~~~~~~~^~~~~~~~~~~~~~~~~\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:415] \u001b[0m\u001b[31mZeroDivisionError: division by zero\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:415] \u001b[0m\u001b[32mLoading AutoregressiveModel from /content/homework/AutoregressiveModel.pth\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:429] \u001b[0m\u001b[32mLoading BSQPatchAutoEncoder from /content/homework/BSQPatchAutoEncoder.pth\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:433] \u001b[0m\u001b[33m  - Check autoregressiveness of the model              [ 0 / 15 ValueError ]\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31mTraceback (most recent call last):\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m  File \"/content/grader/grader.py\", line 64, in wrapper\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m    v = func(self, **a)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m        ^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m  File \"/content/grader/tests.py\", line 154, in test_autoregressiveness\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, num_workers=1, shuffle=True)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 383, in __init__\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\", line 165, in __init__\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31m    raise ValueError(\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:433] \u001b[0m\u001b[31mValueError: num_samples should be a positive integer value, but got num_samples=0\u001b[0m\n",
            "\u001b[97m[INFO     00:00:433] \u001b[0m\u001b[97m --------------------------------------------------    [   0 /  30 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:00:434] \u001b[0m\u001b[97mImage Generation from Autoregressive Model\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:435] \u001b[0m\u001b[32mLoading AutoregressiveModel from /content/homework/AutoregressiveModel.pth\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:447] \u001b[0m\u001b[32mLoading BSQPatchAutoEncoder from /content/homework/BSQPatchAutoEncoder.pth\u001b[0m\n",
            "\u001b[32m[DEBUG    00:00:787] \u001b[0m\u001b[32mgenerating 8 images from the autoregressive model\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:787] \u001b[0m\u001b[33m  - Check image generation from the model              [ 0 / 10 Not Implemented ]\u001b[0m\n",
            "\u001b[97m[INFO     00:00:787] \u001b[0m\u001b[97m --------------------------------------------------    [   0 /  10 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:00:789] \u001b[0m\u001b[97mImage Compression\u001b[0m\n",
            "\u001b[33m[WARNING  00:00:790] \u001b[0m\u001b[33m  - Check image compression ratio and reconstruction quality [ 0 / 5 FileNotFoundError ]\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:790] \u001b[0m\u001b[31mTraceback (most recent call last):\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:790] \u001b[0m\u001b[31m  File \"/content/grader/grader.py\", line 64, in wrapper\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:790] \u001b[0m\u001b[31m    v = func(self, **a)\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:790] \u001b[0m\u001b[31m        ^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:790] \u001b[0m\u001b[31m  File \"/content/grader/tests.py\", line 270, in test_compression\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:790] \u001b[0m\u001b[31m    valid_images = [f for f in os.listdir(self.SOURCE_IMG_DIR) if f.endswith(\".jpg\")]\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:790] \u001b[0m\u001b[31m                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "\u001b[31m[ERROR    00:00:790] \u001b[0m\u001b[31mFileNotFoundError: [Errno 2] No such file or directory: 'data/valid'\u001b[0m\n",
            "\u001b[97m[INFO     00:00:790] \u001b[0m\u001b[97m --------------------------------------------------    [   0 /   5 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:00:790] \u001b[0m\u001b[97mTotal                                                      0 / 105\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}